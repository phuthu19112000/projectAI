{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation\n",
    "\n",
    "Welcome to your first programming assignment for this week! \n",
    "\n",
    "* You will build a Neural Machine Translation (NMT) model to translate human-readable dates (\"25th of June, 2009\") into machine-readable dates (\"2009-06-25\"). \n",
    "* You will do this using an attention model, one of the most sophisticated sequence-to-sequence models. \n",
    "\n",
    "This notebook was produced together with NVIDIA's Deep Learning Institute. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Updates</font>\n",
    "\n",
    "#### If you were working on the notebook before this update...\n",
    "* The current notebook is version \"4a\".\n",
    "* You can find your original work saved in the notebook with the previous version name (\"v4\") \n",
    "* To view the file directory, go to the menu \"File->Open\", and this will open a new tab that shows the file directory.\n",
    "\n",
    "#### List of updates\n",
    "* Clarified names of variables to be consistent with the lectures and consistent within the assignment\n",
    "    - pre-attention bi-directional LSTM: the first LSTM that processes the input data.\n",
    "        - 'a': the hidden state of the pre-attention LSTM.\n",
    "    - post-attention LSTM: the LSTM that outputs the translation.\n",
    "        - 's': the hidden state of the post-attention LSTM.\n",
    "    - energies \"e\".  The output of the dense function that takes \"a\" and \"s\" as inputs.\n",
    "    - All references to \"output activation\" are updated to \"hidden state\".\n",
    "    - \"post-activation\" sequence model is updated to \"post-attention sequence model\".\n",
    "    - 3.1: \"Getting the activations from the Network\" renamed to \"Getting the attention weights from the network.\"\n",
    "    - Appropriate mentions of \"activation\" replaced \"attention weights.\"\n",
    "    - Sequence of alphas corrected to be a sequence of \"a\" hidden states.\n",
    "* one_step_attention:\n",
    "    - Provides sample code for each Keras layer, to show how to call the functions.\n",
    "    - Reminds students to provide the list of hidden states in a specific order, in order to pause the autograder.\n",
    "* model\n",
    "    - Provides sample code for each Keras layer, to show how to call the functions.\n",
    "    - Added a troubleshooting note about handling errors.\n",
    "    - Fixed typo: outputs should be of length 10 and not 11.\n",
    "* define optimizer and compile model\n",
    "    - Provides sample code for each Keras layer, to show how to call the functions.\n",
    "\n",
    "* Spelling, grammar and wording corrections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load all the packages you will need for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "from faker import Faker\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "from nmt_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Translating human readable dates into machine readable dates\n",
    "\n",
    "* Mô hình bạn sẽ xây dựng ở đây có thể được sử dụng để dịch từ ngôn ngữ này sang ngôn ngữ khác, chẳng hạn như dịch từ tiếng Anh sang tiếng Hindi.\n",
    "* Tuy nhiên, việc dịch ngôn ngữ yêu cầu bộ dữ liệu lớn và thường mất nhiều ngày đào tạo về GPU.\n",
    "* Để cung cấp cho bạn một nơi để thử nghiệm với các mô hình này mà không cần sử dụng bộ dữ liệu lớn, chúng tôi sẽ thực hiện tác vụ \"dịch ngày\" đơn giản hơn.\n",
    "* Mạng sẽ nhập ngày tháng được viết bằng nhiều định dạng có thể có (* ví dụ: \"ngày 29 tháng 8 năm 1958\", \"30/03/1968\", \"24 tháng 6 năm 1987\" *)\n",
    "* Mạng sẽ dịch chúng thành các ngày chuẩn hóa, máy có thể đọc được (* ví dụ: \"1958-08-29\", \"1968-03-30\", \"1987-06-24\" *).\n",
    "* Chúng tôi sẽ yêu cầu mạng tìm hiểu để xuất ngày ở định dạng phổ biến mà máy có thể đọc được là YYYY-MM-DD.\n",
    "<!-- \n",
    "Take a look at [nmt_utils.py](./nmt_utils.py) to see all the formatting. Count and figure out how the formats work, you will need this knowledge later. !--> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Dataset\n",
    "\n",
    "We will train the model on a dataset of 10,000 human readable dates and their equivalent, standardized, machine readable dates. Let's run the following cells to load the dataset and print some examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 21224.26it/s]\n"
     ]
    }
   ],
   "source": [
    "m = 10000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('29 april 1975', '1975-04-29'),\n",
       " ('monday april 30 1973', '1973-04-30'),\n",
       " ('tuesday may 25 1982', '1982-05-25'),\n",
       " ('11/13/92', '1992-11-13'),\n",
       " ('saturday march 13 2004', '2004-03-13'),\n",
       " ('thursday december 5 2019', '2019-12-05'),\n",
       " ('21 jun 1971', '1971-06-21'),\n",
       " ('31 03 71', '1971-03-31'),\n",
       " ('thursday august 4 2011', '2011-08-04'),\n",
       " ('saturday march 31 1990', '1990-03-31')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've loaded:\n",
    "- `dataset`: danh sách các bộ giá trị (ngày con người đọc được, ngày máy đọc được).\n",
    "- `human_vocab`: từ điển python ánh xạ tất cả các ký tự được sử dụng trong ngày tháng mà con người có thể đọc được thành một chỉ mục có giá trị số nguyên.\n",
    "- `machine_vocab`: từ điển python ánh xạ tất cả các ký tự được sử dụng trong ngày tháng có thể đọc được của máy thành một chỉ mục có giá trị số nguyên.\n",
    "    - **Note**: Các chỉ số này không nhất thiết phải nhất quán với `human_vocab`. \n",
    "- `inv_machine_vocab`: từ điển nghịch đảo của `machine_vocab`, ánh xạ từ các chỉ số trở lại ký tự.\n",
    "\n",
    "Hãy xử lý trước dữ liệu và ánh xạ dữ liệu văn bản thô thành các giá trị chỉ mục.\n",
    "- We will set Tx=30 \n",
    "    - Chúng tôi giả định Tx là độ dài tối đa của ngày con người có thể đọc được.\n",
    "    - Nếu chúng tôi nhận được một đầu vào dài hơn, chúng tôi sẽ phải cắt bớt nó.\n",
    "- We will set Ty=10\n",
    "    - \"YYYY-MM-DD\" is 10 characters long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (10000, 30)\n",
      "Y.shape: (10000, 10)\n",
      "Xoh.shape: (10000, 30, 37)\n",
      "Yoh.shape: (10000, 10, 11)\n"
     ]
    }
   ],
   "source": [
    "Tx = 30\n",
    "Ty = 10\n",
    "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
    "\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"Y.shape:\", Y.shape)\n",
    "print(\"Xoh.shape:\", Xoh.shape)\n",
    "print(\"Yoh.shape:\", Yoh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have:\n",
    "- `X`: một phiên bản đã xử lý của ngày con người có thể đọc được trong tập huấn luyện.\n",
    "    - Mỗi ký tự trong X được thay thế bằng một chỉ mục (số nguyên) được ánh xạ tới ký tự bằng cách sử dụng `human_vocab`. \n",
    "    - Mỗi ngày đều được đệm để đảm bảo độ dài $T_x$ sử dụng một ký tự đặc biệt (< pad >). \n",
    "    - `X.shape = (m, Tx)` với m là số lượng ví dụ đào tạo trong một batch.\n",
    "- `Y`: một phiên bản đã xử lý của máy có thể đọc được ngày tháng trong tập huấn luyện.\n",
    "    - Mỗi ký tự được thay thế bằng chỉ số (số nguyên) mà nó được ánh xạ tới `machine_vocab`. \n",
    "    - `Y.shape = (m, Ty)`. \n",
    "- `Xoh`: one-hot version of `X`\n",
    "    - Mỗi chỉ mục trong `X` được chuyển đổi thành biểu diễn one-hot (nếu chỉ mục là 2, phiên bản one-hot có vị trí chỉ mục 2 được đặt thành 1, và các vị trí còn lại là 0.\n",
    "    - `Xoh.shape = (m, Tx, len(human_vocab))`\n",
    "- `Yoh`: one-hot version of `Y`\n",
    "    - Mỗi chỉ mục trong `Y` được chuyển đổi thành biểu diễn one-hot.\n",
    "    - `Yoh.shape = (m, Tx, len(machine_vocab))`. \n",
    "    - `len(machine_vocab) = 11` vì có 10 chữ số (0 đến 9) và ký hiệu `-`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hãy cũng xem xét một số ví dụ về các ví dụ đào tạo tiền xử lý.\n",
    "* Hãy thoải mái chơi với `index` trong ô bên dưới để điều hướng tập dữ liệu và xem ngày nguồn / đích được xử lý trước như thế nào."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source date: 29 april 1975\n",
      "Target date: 1975-04-29\n",
      "\n",
      "Source after preprocessing (indices): [ 5 12  0 13 27 28 21 23  0  4 12 10  8 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36]\n",
      "Target after preprocessing (indices): [ 2 10  8  6  0  1  5  0  3 10]\n",
      "\n",
      "Source after preprocessing (one-hot): [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]]\n",
      "Target after preprocessing (one-hot): [[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(\"Source date:\", dataset[index][0])\n",
    "print(\"Target date:\", dataset[index][1])\n",
    "print()\n",
    "print(\"Source after preprocessing (indices):\", X[index])\n",
    "print(\"Target after preprocessing (indices):\", Y[index])\n",
    "print()\n",
    "print(\"Source after preprocessing (one-hot):\", Xoh[index])\n",
    "print(\"Target after preprocessing (one-hot):\", Yoh[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Neural machine translation with attention\n",
    "\n",
    "* Nếu bạn phải dịch một đoạn sách từ tiếng Pháp sang tiếng Anh, bạn sẽ không đọc hết đoạn văn, sau đó đóng sách và dịch.\n",
    "* Ngay cả trong quá trình dịch, bạn sẽ đọc / đọc lại và tập trung vào các phần của đoạn tiếng Pháp tương ứng với phần tiếng Anh mà bạn đang viết ra.\n",
    "* Cơ chế attention cho mô hình Dịch máy thần kinh biết nơi nó cần chú ý đến ở bất kỳ bước nào.\n",
    "\n",
    "\n",
    "### 2.1 - Attention mechanism\n",
    "\n",
    "Trong phần này, bạn sẽ thực hiện cơ chế attention được trình bày trong các video bài giảng.\n",
    "* Đây là một con số để nhắc nhở bạn cách hoạt động của mô hình.\n",
    "    * Biểu đồ bên trái cho thấy mô hình attention.\n",
    "    * Biểu đồ bên phải cho thấy một bước \"attention\" thực hiện để tính toán các biến attention $\\alpha^{\\langle t, t' \\rangle}$.\n",
    "    * The attention variables $\\alpha^{\\langle t, t' \\rangle}$ are used to compute the context variable $context^{\\langle t \\rangle}$ cho mỗi bước thời gian trong đầu ra ($t=1, \\ldots, T_y$). \n",
    "\n",
    "<table>\n",
    "<td> \n",
    "<img src=\"images/attn_model.png\" style=\"width:500;height:500px;\"> <br>\n",
    "</td> \n",
    "<td> \n",
    "<img src=\"images/attn_mechanism.png\" style=\"width:500;height:500px;\"> <br>\n",
    "</td> \n",
    "</table>\n",
    "<caption><center> **Figure 1**: Neural machine translation with attention</center></caption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dưới đây là một số thuộc tính của mô hình mà bạn có thể nhận thấy:\n",
    "\n",
    "#### Pre-attention and Post-attention LSTMs on both sides of the attention mechanism\n",
    "- Có hai LSTM riêng biệt trong mô hình này (xem sơ đồ bên trái): pre-attention and post-attention LSTMs.\n",
    "- *Pre-attention* Bi-LSTM là một trong những ở dưới cùng của hình ảnh là một LSTM hai hướng và đi kèm *before* cơ chế chú ý.\n",
    "    - Cơ chế attention được hiển thị ở giữa sơ đồ bên trái.\n",
    "    - The pre-attention Bi-LSTM trải qua $T_x$ time steps\n",
    "- *Post-attention* LSTM: ở đầu sơ đồ đi kèm *after* cơ chế chú ý.\n",
    "    - The post-attention LSTM trai qua  $T_y$ time steps. \n",
    "\n",
    "- The post-attention LSTM passes the hidden state $s^{\\langle t \\rangle}$ and cell state $c^{\\langle t \\rangle}$ from one time step to the next. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM có cả trạng thái ẩn và trạng thái cell\n",
    "* Trong các video bài giảng, chúng tôi chỉ sử dụng RNN cơ bản cho the post-attention sequence model\n",
    "    * Điều này có nghĩa là trạng thái được RNN nắm bắt chỉ xuất ra trạng thái ẩn $s^{\\langle t\\rangle}$. \n",
    "* Trong bài tập này, chúng tôi đang sử dụng LSTM thay vì RNN cơ bản.\n",
    "    * Vì vậy, LSTM có cả trạng thái ẩn $s^{\\langle t\\rangle}$ and the cell state $c^{\\langle t\\rangle}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mỗi bước thời gian không sử dụng dự đoán từ bước thời gian trước đó\n",
    "* Không giống như các ví dụ tạo văn bản trước đó trong khóa học, trong mô hình này, the post-attention LSTM tại thời điểm $t$ không thực hiện dự đoán của bước thời gian trước đó $y^{\\langle t-1 \\rangle}$ as input.\n",
    "* The post-attention LSTM tại thời điểm 't' chỉ có trạng thái ẩn $s^{\\langle t\\rangle}$ and cell state $c^{\\langle t\\rangle}$ as input. \n",
    "* Chúng tôi đã thiết kế mô hình theo cách này bởi vì không giống như tạo ngôn ngữ (trong đó các ký tự liền kề có tương quan cao), không có sự phụ thuộc mạnh mẽ giữa ký tự trước và ký tự tiếp theo trong ngày YYYY-MM-DD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kết hợp các trạng thái ẩn từ LSTM trước và sau chú ý\n",
    "- $\\overrightarrow{a}^{\\langle t \\rangle}$: trạng thái ẩn của hướng chuyển tiếp, pre-attention LSTM.\n",
    "- $\\overleftarrow{a}^{\\langle t \\rangle}$: trạng thái ẩn của hướng lùi, pre-attention LSTM.\n",
    "- $a^{\\langle t \\rangle} = [\\overrightarrow{a}^{\\langle t \\rangle}, \\overleftarrow{a}^{\\langle t \\rangle}]$: sự kết hợp của các hoạt động của cả hai hướng về phía trước $\\overrightarrow{a}^{\\langle t \\rangle}$ và hướng lùi $\\overleftarrow{a}^{\\langle t \\rangle}$ of the pre-attention Bi-LSTM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing \"energies\" $e^{\\langle t, t' \\rangle}$ as a function of $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t' \\rangle}$\n",
    "- Recall in the lesson videos \"Attention Model\", at time 6:45 to 8:16, the definition of \"e\" as a function of $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$.\n",
    "    - \"e\" is called the \"energies\" variable.\n",
    "    - $s^{\\langle t-1 \\rangle}$ is the hidden state of the post-attention LSTM\n",
    "    - $a^{\\langle t' \\rangle}$ is the hidden state of the pre-attention LSTM.\n",
    "    - $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$ được đưa vào một mạng nơ-ron đơn giản, mạng này học hàm để xuất ra $e^{\\langle t, t' \\rangle}$.\n",
    "    - $e^{\\langle t, t' \\rangle}$ is then used when computing the attention $a^{\\langle t, t' \\rangle}$ that $y^{\\langle t \\rangle}$ should pay to $a^{\\langle t' \\rangle}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The diagram on the right of figure 1 uses a `RepeatVector` node to copy $s^{\\langle t-1 \\rangle}$'s value $T_x$ times.\n",
    "- Then it uses `Concatenation` to concatenate $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$.\n",
    "- The concatenation of $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$ is fed into a \"Dense\" layer, which computes $e^{\\langle t, t' \\rangle}$. \n",
    "- $e^{\\langle t, t' \\rangle}$ is then passed through a softmax to compute $\\alpha^{\\langle t, t' \\rangle}$.\n",
    "- Lưu ý rằng sơ đồ không hiển thị rõ ràng biến $e^{\\langle t, t' \\rangle}$, but $e^{\\langle t, t' \\rangle}$ nằm trên lớp Dense và bên dưới lớp Softmax trong biểu đồ ở nửa bên phải của hình 1.\n",
    "- Chúng tôi sẽ giải thích cách sử dụng`RepeatVector` and `Concatenation` in Keras below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation Details\n",
    "   \n",
    "Let's implement this neural translator. You will start by implementing two functions: `one_step_attention()` and `model()`.\n",
    "\n",
    "#### one_step_attention\n",
    "* The inputs to the one_step_attention at time step $t$ are:\n",
    "    - $[a^{<1>},a^{<2>}, ..., a^{<T_x>}]$: all hidden states of the pre-attention Bi-LSTM.\n",
    "    - $s^{<t-1>}$: the previous hidden state of the post-attention LSTM \n",
    "* one_step_attention computes:\n",
    "    - $[\\alpha^{<t,1>},\\alpha^{<t,2>}, ..., \\alpha^{<t,T_x>}]$: the attention weights\n",
    "    - $context^{ \\langle t \\rangle }$: the context vector:\n",
    "    \n",
    "$$context^{<t>} = \\sum_{t' = 1}^{T_x} \\alpha^{<t,t'>}a^{<t'>}\\tag{1}$$ \n",
    "\n",
    "##### Clarifying 'context' and 'c'\n",
    "- Trong các video bài giảng, context được biểu thị $c^{\\langle t \\rangle}$\n",
    "- Trong bài tập, chúng tôi đang gọi context $context^{\\langle t \\rangle}$.\n",
    "    - Điều này để tránh nhầm lẫn với biến ô bộ nhớ trong của post-attention LSTM, biến này cũng được ký hiệu là $c^{\\langle t \\rangle}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement `one_step_attention`\n",
    "\n",
    "**Exercise**: Implement `one_step_attention()`. \n",
    "\n",
    "* The function `model()` will call the layers in `one_step_attention()` $T_y$ using a for-loop.\n",
    "* Điều quan trọng là tất cả các bản sao $T_y$ có cùng trọng số.\n",
    "    * Nó không nên bắt đầu lại trọng số mỗi lần.\n",
    "    * Nói cách khác, tất cả các bước $T_y$ phải có trọng số chung.\n",
    "* Đây là cách bạn có thể triển khai các lớp với trọng số có thể chia sẻ trong Keras:\n",
    "    1. Define the layer objects in a variable scope that is outside of the `one_step_attention` function.  Ví dụ: xác định các đối tượng là biến toàn cục sẽ hoạt động.\n",
    "        - Lưu ý rằng việc xác định các biến này bên trong phạm vi của hàm `model` về mặt kỹ thuật sẽ hoạt động, vì `model` will then call the `one_step_attention` function.  Với mục đích làm cho việc phân loại và khắc phục sự cố dễ dàng hơn, chúng tôi định nghĩa chúng là các biến toàn cục.\n",
    "    2.Gọi các đối tượng này khi truyền đầu vào.\n",
    "* Chúng tôi đã xác định các lớp bạn cần làm biến toàn cục. \n",
    "    * Please run the following cells to create them. \n",
    "    * Xin lưu ý rằng trình chấm điểm tự động mong đợi các biến toàn cục này với các tên biến đã cho. Với mục đích chấm điểm, vui lòng không đổi tên các biến toàn cục.\n",
    "* Vui lòng kiểm tra tài liệu Keras để tìm hiểu thêm về các lớp này. Các lớp là các chức năng. Dưới đây là các ví dụ về cách gọi các hàm này.\n",
    "    * [RepeatVector()](https://keras.io/layers/core/#repeatvector)\n",
    "```Python\n",
    "var_repeated = repeat_layer(var1)\n",
    "```\n",
    "    * [Concatenate()](https://keras.io/layers/merge/#concatenate)   \n",
    "```Python\n",
    "concatenated_vars = concatenate_layer([var1,var2,var3])\n",
    "```\n",
    "    * [Dense()](https://keras.io/layers/core/#dense)  \n",
    "```Python\n",
    "var_out = dense_layer(var_in)\n",
    "```\n",
    "    * [Activation()](https://keras.io/layers/core/#activation)  \n",
    "```Python\n",
    "activation = activation_layer(var_in)  \n",
    "```\n",
    "    * [Dot()](https://keras.io/layers/merge/#dot)  \n",
    "```Python\n",
    "dot_product = dot_layer([var1,var2])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Các lớp chia sẻ được xác định dưới dạng biến toàn cục\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor1 = Dense(10, activation = \"tanh\")\n",
    "densor2 = Dense(1, activation = \"relu\")\n",
    "activator = Activation(softmax, name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: one_step_attention\n",
    "\n",
    "def one_step_attention(a, s_prev):\n",
    "    \"\"\"\n",
    "    Thực hiện một bước chú ý: Xuất ra một vectơ ngữ cảnh được tính dưới dạng dot product của trọng số chú ý\n",
    "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
    "    \n",
    "    Arguments:\n",
    "    a -- đầu ra trạng thái ẩn của Bi-LSTM, mảng hình dạng numpy (m, Tx, 2*n_a)\n",
    "    s_prev -- trạng thái ẩn trước đó của LSTM (post-attention), mảng hình dạng (m, n_s)\n",
    "    \n",
    "    Returns:\n",
    "    context -- context vector, input of the next (post-attention) LSTM cell\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sử dụng bộ lặp để lặp lại s_prev có hình dạng (m, Tx, n_s) để bạn có thể nối nó với tất cả các trạng thái ẩn \"a\"\n",
    "    s_prev = repeator(s_prev)\n",
    "    # Sử dụng bộ nối để nối a và s_prev trên trục cuối cùng \n",
    "    concat = concatenator([a,s_prev])\n",
    "    # Sử dụng densor1 để truyền concat thông qua một mạng nơron nhỏ được kết nối đầy đủ để tính biến \"năng lượng trung gian\" e.\n",
    "    e = densor1(concat)\n",
    "    # Sử dụng densor2 để truyền e thông qua một mạng nơron nhỏ được kết nối đầy đủ để tính toán các năng lượng biến đổi \"năng lượng\".\n",
    "    energies = densor2(e)\n",
    "    # Use \"activator\" on \"energies\" để tính toán trọng số chú ý \"alphas\"\n",
    "    alphas = activator(energies)\n",
    "    # Sử dụng dotor cùng với \"alphas\" và \"a\" để tính toán vector ngữ cảnh sẽ được cấp cho LSTM-ô tiếp theo\n",
    "    context = dotor([alphas,a])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bạn sẽ có thể kiểm tra kết quả mong đợi của one_step_attention() sau khi bạn đã mã hóa hàm model()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model\n",
    "* `model` first runs the input through a Bi-LSTM to get $[a^{<1>},a^{<2>}, ..., a^{<T_x>}]$. \n",
    "* Then, `model` calls `one_step_attention()` $T_y$ times using a `for` loop.  Tại mỗi lần lặp lại của vòng lặp này:\n",
    "    - It gives the computed context vector $context^{<t>}$ to the post-attention LSTM.\n",
    "    - It runs the output of the post-attention LSTM through a dense layer with softmax activation.\n",
    "    - The softmax generates a prediction $\\hat{y}^{<t>}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Implement `model()` như giải thích trong hình 1 và văn bản ở trên. Một lần nữa, chúng tôi đã xác định các lớp toàn cục sẽ chia sẻ trọng số được sử dụng trong `model()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_a = 32 # number of units for the pre-attention, bi-directional LSTM's hidden state 'a'\n",
    "n_s = 64 # number of units for the post-attention LSTM's hidden state \"s\"\n",
    "\n",
    "# Please note, this is the post attention LSTM cell.  \n",
    "post_activation_LSTM_cell = LSTM(n_s, return_state = True) # post-attention LSTM \n",
    "output_layer = Dense(len(machine_vocab), activation=softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ bạn có thể sử dụng các lớp này $ T_y $ times trong một `for` loop để tạo đầu ra và các tham số của chúng sẽ không được khởi động lại. Bạn sẽ phải thực hiện các bước sau:\n",
    "\n",
    "1. Tuyên truyền đầu vào `X` into a bi-directional LSTM.\n",
    "    * [Bidirectional](https://keras.io/layers/wrappers/#bidirectional) \n",
    "    * [LSTM](https://keras.io/layers/recurrent/#lstm)\n",
    "    * Hãy nhớ rằng chúng tôi muốn LSTM trả về một chuỗi đầy đủ thay vì chỉ trạng thái ẩn cuối cùng.  \n",
    "    \n",
    "Sample code:\n",
    "\n",
    "```Python\n",
    "sequence_of_hidden_states = Bidirectional(LSTM(units=..., return_sequences=...))(the_input_X)\n",
    "```\n",
    "    \n",
    "2. Iterate for $t = 0, \\cdots, T_y-1$: \n",
    "    1. Call `one_step_attention()`, passing in the sequence of hidden states $[a^{\\langle 1 \\rangle},a^{\\langle 2 \\rangle}, ..., a^{ \\langle T_x \\rangle}]$ from the pre-attention bi-directional LSTM, and the previous hidden state $s^{<t-1>}$ from the post-attention LSTM to calculate the context vector $context^{<t>}$.\n",
    "    2. Give $context^{<t>}$ to the post-attention LSTM cell. \n",
    "        - Hãy nhớ pass qua ở trạng thái ẩn trước đó $s^{\\langle t-1\\rangle}$ and cell-states $c^{\\langle t-1\\rangle}$ of this LSTM \n",
    "        * Điều này xuất ra trạng thái ẩn mới $s^{<t>}$ và trạng thái cell mới $c^{<t>}$.  \n",
    "\n",
    "        Sample code:\n",
    "        ```Python\n",
    "        next_hidden_state, _ , next_cell_state = \n",
    "            post_activation_LSTM_cell(inputs=..., initial_state=[prev_hidden_state, prev_cell_state])\n",
    "        ```   \n",
    "        Please note that the layer is actually the \"post attention LSTM cell\".  For the purposes of passing the automatic grader, please do not modify the naming of this global variable.  This will be fixed when we deploy updates to the automatic grader.\n",
    "    3. Apply a dense, softmax layer to $s^{<t>}$, get the output.  \n",
    "        Sample code:\n",
    "        ```Python\n",
    "        output = output_layer(inputs=...)\n",
    "        ```\n",
    "    4. Save the output by adding it to the list of outputs.\n",
    "\n",
    "3. Create your Keras model instance.\n",
    "    * It should have three inputs:\n",
    "        * `X`, the one-hot encoded inputs to the model, of shape ($T_{x}, humanVocabSize)$\n",
    "        * $s^{\\langle 0 \\rangle}$, the initial hidden state of the post-attention LSTM\n",
    "        * $c^{\\langle 0 \\rangle}$), the initial cell state of the post-attention LSTM\n",
    "    * The output is the list of outputs.  \n",
    "    Sample code\n",
    "    ```Python\n",
    "    model = Model(inputs=[...,...,...], outputs=...)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Tx -- length of the input sequence\n",
    "    Ty -- length of the output sequence\n",
    "    n_a -- hidden state size of the Bi-LSTM\n",
    "    n_s -- hidden state size of the post-attention LSTM\n",
    "    human_vocab_size -- size of the python dictionary \"human_vocab\"\n",
    "    machine_vocab_size -- size of the python dictionary \"machine_vocab\"\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Xác định các đầu vào của mô hình của bạn với một hình dạng (Tx,)\n",
    "    # Define s0 (initial hidden state) and c0 (initial cell state)\n",
    "    # for the decoder LSTM with shape (n_s,)\n",
    "    X = Input(shape=(Tx, human_vocab_size))\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    # Initialize empty list of outputs\n",
    "    outputs = []\n",
    "    \n",
    "    # Step 1: Define your pre-attention Bi-LSTM. (≈ 1 line)\n",
    "    a = Bidirectional(LSTM(n_a, return_sequences=True))(X)          \n",
    "    \n",
    "    # Step 2: Iterate for Ty steps\n",
    "    for t in range(Ty):\n",
    "    \n",
    "        # Step 2.A: Thực hiện một bước của cơ chế chú ý để lấy lại vectơ ngữ cảnh ở bước t\n",
    "        context = one_step_attention(a, s)\n",
    "        \n",
    "        # Step 2.B: Apply the post-attention LSTM cell to the \"context\" vector.\n",
    "        # Don't forget to pass: initial_state = [hidden state, cell state] (≈ 1 line)\n",
    "        s, _, c = post_activation_LSTM_cell(context, initial_state=[s,c])\n",
    "        \n",
    "        # Step 2.C: Apply Dense layer to the hidden state output of the post-attention LSTM (≈ 1 line)\n",
    "        out = output_layer(s)\n",
    "        \n",
    "        # Step 2.D: Append \"out\" to the \"outputs\" list (≈ 1 line)\n",
    "        outputs.append( out )\n",
    "    \n",
    "    # Step 3: Create model instance taking three inputs and returning the list of outputs. (≈ 1 line)\n",
    "    model = Model(inputs=[X,s0,c0], outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to create your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a summary of the model to check if it matches the expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 30, 37)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "s0 (InputLayer)                  (None, 64)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional)  (None, 30, 64)        17920       input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "repeat_vector_3 (RepeatVector)   (None, 30, 64)        0           s0[0][0]                         \n",
      "                                                                   lstm_3[0][0]                     \n",
      "                                                                   lstm_3[1][0]                     \n",
      "                                                                   lstm_3[2][0]                     \n",
      "                                                                   lstm_3[3][0]                     \n",
      "                                                                   lstm_3[4][0]                     \n",
      "                                                                   lstm_3[5][0]                     \n",
      "                                                                   lstm_3[6][0]                     \n",
      "                                                                   lstm_3[7][0]                     \n",
      "                                                                   lstm_3[8][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 30, 128)       0           bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_3[0][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_3[1][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_3[2][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_3[3][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_3[4][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_3[5][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_3[6][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_3[7][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_3[8][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_3[9][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 30, 10)        1290        concatenate_3[0][0]              \n",
      "                                                                   concatenate_3[1][0]              \n",
      "                                                                   concatenate_3[2][0]              \n",
      "                                                                   concatenate_3[3][0]              \n",
      "                                                                   concatenate_3[4][0]              \n",
      "                                                                   concatenate_3[5][0]              \n",
      "                                                                   concatenate_3[6][0]              \n",
      "                                                                   concatenate_3[7][0]              \n",
      "                                                                   concatenate_3[8][0]              \n",
      "                                                                   concatenate_3[9][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 30, 1)         11          dense_6[0][0]                    \n",
      "                                                                   dense_6[1][0]                    \n",
      "                                                                   dense_6[2][0]                    \n",
      "                                                                   dense_6[3][0]                    \n",
      "                                                                   dense_6[4][0]                    \n",
      "                                                                   dense_6[5][0]                    \n",
      "                                                                   dense_6[6][0]                    \n",
      "                                                                   dense_6[7][0]                    \n",
      "                                                                   dense_6[8][0]                    \n",
      "                                                                   dense_6[9][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "attention_weights (Activation)   (None, 30, 1)         0           dense_7[0][0]                    \n",
      "                                                                   dense_7[1][0]                    \n",
      "                                                                   dense_7[2][0]                    \n",
      "                                                                   dense_7[3][0]                    \n",
      "                                                                   dense_7[4][0]                    \n",
      "                                                                   dense_7[5][0]                    \n",
      "                                                                   dense_7[6][0]                    \n",
      "                                                                   dense_7[7][0]                    \n",
      "                                                                   dense_7[8][0]                    \n",
      "                                                                   dense_7[9][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dot_3 (Dot)                      (None, 1, 64)         0           attention_weights[0][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[1][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[2][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[3][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[4][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[5][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[6][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[7][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[8][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[9][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "c0 (InputLayer)                  (None, 64)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    [(None, 64), (None, 6 33024       dot_3[0][0]                      \n",
      "                                                                   s0[0][0]                         \n",
      "                                                                   c0[0][0]                         \n",
      "                                                                   dot_3[1][0]                      \n",
      "                                                                   lstm_3[0][0]                     \n",
      "                                                                   lstm_3[0][2]                     \n",
      "                                                                   dot_3[2][0]                      \n",
      "                                                                   lstm_3[1][0]                     \n",
      "                                                                   lstm_3[1][2]                     \n",
      "                                                                   dot_3[3][0]                      \n",
      "                                                                   lstm_3[2][0]                     \n",
      "                                                                   lstm_3[2][2]                     \n",
      "                                                                   dot_3[4][0]                      \n",
      "                                                                   lstm_3[3][0]                     \n",
      "                                                                   lstm_3[3][2]                     \n",
      "                                                                   dot_3[5][0]                      \n",
      "                                                                   lstm_3[4][0]                     \n",
      "                                                                   lstm_3[4][2]                     \n",
      "                                                                   dot_3[6][0]                      \n",
      "                                                                   lstm_3[5][0]                     \n",
      "                                                                   lstm_3[5][2]                     \n",
      "                                                                   dot_3[7][0]                      \n",
      "                                                                   lstm_3[6][0]                     \n",
      "                                                                   lstm_3[6][2]                     \n",
      "                                                                   dot_3[8][0]                      \n",
      "                                                                   lstm_3[7][0]                     \n",
      "                                                                   lstm_3[7][2]                     \n",
      "                                                                   dot_3[9][0]                      \n",
      "                                                                   lstm_3[8][0]                     \n",
      "                                                                   lstm_3[8][2]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 11)            715         lstm_3[0][0]                     \n",
      "                                                                   lstm_3[1][0]                     \n",
      "                                                                   lstm_3[2][0]                     \n",
      "                                                                   lstm_3[3][0]                     \n",
      "                                                                   lstm_3[4][0]                     \n",
      "                                                                   lstm_3[5][0]                     \n",
      "                                                                   lstm_3[6][0]                     \n",
      "                                                                   lstm_3[7][0]                     \n",
      "                                                                   lstm_3[8][0]                     \n",
      "                                                                   lstm_3[9][0]                     \n",
      "====================================================================================================\n",
      "Total params: 52,960\n",
      "Trainable params: 52,960\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "Here is the summary you should see\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **Total params:**\n",
    "        </td>\n",
    "        <td>\n",
    "         52,960\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **Trainable params:**\n",
    "        </td>\n",
    "        <td>\n",
    "         52,960\n",
    "        </td>\n",
    "    </tr>\n",
    "            <tr>\n",
    "        <td>\n",
    "            **Non-trainable params:**\n",
    "        </td>\n",
    "        <td>\n",
    "         0\n",
    "        </td>\n",
    "    </tr>\n",
    "                    <tr>\n",
    "        <td>\n",
    "            **bidirectional_1's output shape **\n",
    "        </td>\n",
    "        <td>\n",
    "         (None, 30, 64)  \n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **repeat_vector_1's output shape **\n",
    "        </td>\n",
    "        <td>\n",
    "         (None, 30, 64) \n",
    "        </td>\n",
    "    </tr>\n",
    "                <tr>\n",
    "        <td>\n",
    "            **concatenate_1's output shape **\n",
    "        </td>\n",
    "        <td>\n",
    "         (None, 30, 128) \n",
    "        </td>\n",
    "    </tr>\n",
    "            <tr>\n",
    "        <td>\n",
    "            **attention_weights's output shape **\n",
    "        </td>\n",
    "        <td>\n",
    "         (None, 30, 1)  \n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **dot_1's output shape **\n",
    "        </td>\n",
    "        <td>\n",
    "         (None, 1, 64)\n",
    "        </td>\n",
    "    </tr>\n",
    "           <tr>\n",
    "        <td>\n",
    "            **dense_3's output shape **\n",
    "        </td>\n",
    "        <td>\n",
    "         (None, 11) \n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model\n",
    "* Sau khi tạo mô hình của bạn trong Keras, bạn cần phải compile nó và xác định hàm mất mát, trình tối ưu hóa và metrics bạn muốn sử dụng.\n",
    "    * Loss function: 'categorical_crossentropy'.\n",
    "    * Optimizer: [Adam](https://keras.io/optimizers/#adam) [optimizer](https://keras.io/optimizers/#usage-of-optimizers)\n",
    "        - learning rate = 0.005 \n",
    "        - $\\beta_1 = 0.9$\n",
    "        - $\\beta_2 = 0.999$\n",
    "        - decay = 0.01  \n",
    "    * metric: 'accuracy'\n",
    "    \n",
    "Sample code\n",
    "```Python\n",
    "optimizer = Adam(lr=..., beta_1=..., beta_2=..., decay=...)\n",
    "model.compile(optimizer=..., loss=..., metrics=[...])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam()\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define inputs and outputs, and fit the model\n",
    "Bước cuối cùng là xác định tất cả các đầu vào và đầu ra của bạn để fit với mô hình:\n",
    "- You have input X of shape $(m = 10000, T_x = 30)$ containing the training examples.\n",
    "- You need to create `s0` and `c0` to initialize your `post_attention_LSTM_cell` with zeros.\n",
    "- Given the `model()` you coded, you need the \"outputs\" to be a list of 10 elements of shape (m, T_y). \n",
    "    - The list `outputs[i][0], ..., outputs[i][Ty]` đại diện cho các nhãn thực (characters) tương ứng với $i^{th}$ training example (`X[i]`). \n",
    "    - `outputs[i][j]` là nhãn thực sự của $j^{th}$ character in the $i^{th}$ training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "outputs = list(Yoh.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now fit the model and run it for one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10000/10000 [==============================] - 54s - loss: 20.9687 - dense_8_loss_1: 2.0222 - dense_8_loss_2: 1.8218 - dense_8_loss_3: 2.2215 - dense_8_loss_4: 2.7234 - dense_8_loss_5: 1.4458 - dense_8_loss_6: 1.7928 - dense_8_loss_7: 2.7102 - dense_8_loss_8: 1.4447 - dense_8_loss_9: 1.9864 - dense_8_loss_10: 2.7999 - dense_8_acc_1: 0.2575 - dense_8_acc_2: 0.3681 - dense_8_acc_3: 0.1427 - dense_8_acc_4: 0.0641 - dense_8_acc_5: 0.8683 - dense_8_acc_6: 0.0668 - dense_8_acc_7: 0.0103 - dense_8_acc_8: 0.8807 - dense_8_acc_9: 0.0806 - dense_8_acc_10: 0.0391    \n",
      "Epoch 2/5\n",
      "10000/10000 [==============================] - 53s - loss: 13.8108 - dense_8_loss_1: 0.7757 - dense_8_loss_2: 0.7867 - dense_8_loss_3: 1.6596 - dense_8_loss_4: 2.5390 - dense_8_loss_5: 0.3331 - dense_8_loss_6: 0.7849 - dense_8_loss_7: 2.5214 - dense_8_loss_8: 0.5297 - dense_8_loss_9: 1.4764 - dense_8_loss_10: 2.4043 - dense_8_acc_1: 0.6904 - dense_8_acc_2: 0.7627 - dense_8_acc_3: 0.3115 - dense_8_acc_4: 0.1026 - dense_8_acc_5: 1.0000 - dense_8_acc_6: 0.6689 - dense_8_acc_7: 0.1185 - dense_8_acc_8: 0.9807 - dense_8_acc_9: 0.3921 - dense_8_acc_10: 0.1330    \n",
      "Epoch 3/5\n",
      "10000/10000 [==============================] - 52s - loss: 9.5165 - dense_8_loss_1: 0.2588 - dense_8_loss_2: 0.2300 - dense_8_loss_3: 1.1775 - dense_8_loss_4: 2.2516 - dense_8_loss_5: 0.0303 - dense_8_loss_6: 0.2798 - dense_8_loss_7: 1.9202 - dense_8_loss_8: 0.0270 - dense_8_loss_9: 1.1144 - dense_8_loss_10: 2.2268 - dense_8_acc_1: 0.9446 - dense_8_acc_2: 0.9502 - dense_8_acc_3: 0.4882 - dense_8_acc_4: 0.1741 - dense_8_acc_5: 1.0000 - dense_8_acc_6: 0.9225 - dense_8_acc_7: 0.3242 - dense_8_acc_8: 1.0000 - dense_8_acc_9: 0.5014 - dense_8_acc_10: 0.1789    \n",
      "Epoch 4/5\n",
      "10000/10000 [==============================] - 53s - loss: 8.5205 - dense_8_loss_1: 0.1381 - dense_8_loss_2: 0.1341 - dense_8_loss_3: 1.0162 - dense_8_loss_4: 2.1243 - dense_8_loss_5: 0.0160 - dense_8_loss_6: 0.1943 - dense_8_loss_7: 1.7296 - dense_8_loss_8: 0.0130 - dense_8_loss_9: 1.0027 - dense_8_loss_10: 2.1521 - dense_8_acc_1: 0.9633 - dense_8_acc_2: 0.9643 - dense_8_acc_3: 0.5622 - dense_8_acc_4: 0.2262 - dense_8_acc_5: 1.0000 - dense_8_acc_6: 0.9461 - dense_8_acc_7: 0.3742 - dense_8_acc_8: 1.0000 - dense_8_acc_9: 0.5582 - dense_8_acc_10: 0.2107    \n",
      "Epoch 5/5\n",
      "10000/10000 [==============================] - 53s - loss: 8.0136 - dense_8_loss_1: 0.1121 - dense_8_loss_2: 0.1119 - dense_8_loss_3: 0.9533 - dense_8_loss_4: 2.0500 - dense_8_loss_5: 0.0112 - dense_8_loss_6: 0.1567 - dense_8_loss_7: 1.5985 - dense_8_loss_8: 0.0088 - dense_8_loss_9: 0.9293 - dense_8_loss_10: 2.0817 - dense_8_acc_1: 0.9679 - dense_8_acc_2: 0.9691 - dense_8_acc_3: 0.5890 - dense_8_acc_4: 0.2555 - dense_8_acc_5: 1.0000 - dense_8_acc_6: 0.9552 - dense_8_acc_7: 0.4093 - dense_8_acc_8: 1.0000 - dense_8_acc_9: 0.5949 - dense_8_acc_10: 0.2304    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc8453039b0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([Xoh, s0, c0], outputs, epochs=5, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong khi đào tạo, bạn có thể thấy sự mất mát cũng như độ chính xác trên từng vị trí trong số 10 vị trí của đầu ra. Bảng dưới đây cung cấp cho bạn một ví dụ về độ chính xác có thể là bao nhiêu nếu batch có 2 ví dụ:\n",
    "<img src=\"images/table.png\" style=\"width:700;height:200px;\"> <br>\n",
    "<caption><center>Thus, `dense_2_acc_8: 0.89` means that you are predicting the 7th character of the output correctly 89% of the time in the current batch of data. </center></caption>\n",
    "\n",
    "\n",
    "Chúng tôi đã chạy mô hình này lâu hơn và đã tiết kiệm được trọng số. Chạy ô tiếp theo để tải trọng số của chúng tôi. (Bằng cách đào tạo một mô hình trong vài phút, bạn sẽ có thể có được một mô hình có độ chính xác tương tự, nhưng việc tải mô hình của chúng tôi sẽ giúp bạn tiết kiệm thời gian.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('models/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now see the results on new examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: 3 May 1979\n",
      "output: 1979-05-03 \n",
      "\n",
      "source: 5 April 09\n",
      "output: 2009-05-05 \n",
      "\n",
      "source: 21th of August 2016\n",
      "output: 2016-08-21 \n",
      "\n",
      "source: Tue 10 Jul 2007\n",
      "output: 2007-07-10 \n",
      "\n",
      "source: Saturday May 9 2018\n",
      "output: 2018-05-09 \n",
      "\n",
      "source: March 3 2001\n",
      "output: 2001-03-03 \n",
      "\n",
      "source: March 3rd 2001\n",
      "output: 2001-03-03 \n",
      "\n",
      "source: 1 March 2001\n",
      "output: 2001-03-01 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
    "for example in EXAMPLES:\n",
    "    \n",
    "    source = string_to_int(example, Tx, human_vocab)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n",
    "    prediction = model.predict([source, s0, c0])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "    \n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bạn cũng có thể thay đổi các ví dụ này để kiểm tra bằng các ví dụ của riêng bạn. Phần tiếp theo sẽ cho bạn hiểu rõ hơn về cơ chế chú ý đang làm gì - tức là phần đầu vào nào mà mạng đang chú ý khi tạo một ký tự đầu ra cụ thể."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Visualizing Attention (Optional / Ungraded)\n",
    "\n",
    "Vì bài toán có độ dài đầu ra cố định là 10, nên cũng có thể thực hiện nhiệm vụ này bằng cách sử dụng 10 đơn vị softmax khác nhau để tạo ra 10 ký tự của đầu ra. Nhưng một ưu điểm của mô hình chú ý là mỗi phần của đầu ra (chẳng hạn như tháng) biết rằng nó chỉ cần phụ thuộc vào một phần nhỏ của đầu vào (các ký tự trong đầu vào cho biết tháng). Chúng ta có thể hình dung từng phần của đầu ra đang xem phần nào của đầu vào.\n",
    "\n",
    "Cân nhắc nhiệm vụ phiên dịch \"Saturday 9 May 2018\" to \"2018-05-09\". Nếu chúng ta hình dung máy tính $\\alpha^{\\langle t, t' \\rangle}$ we get this: \n",
    "\n",
    "<img src=\"images/date_attention.png\" style=\"width:600;height:300px;\"> <br>\n",
    "<caption><center> **Figure 8**: Full Attention Map</center></caption>\n",
    "\n",
    "Lưu ý cách đầu ra bỏ qua phần \"Saturday\" của đầu vào. Không có bước thời gian đầu ra nào chú ý nhiều đến phần đầu vào đó. Chúng tôi cũng thấy rằng 9 đã được dịch là 09 và May đã được dịch chính xác thành 05, với đầu ra chú ý đến các phần của đầu vào mà nó cần để thực hiện bản dịch. Phần lớn yêu cầu năm phải chú ý đến \"18\" của đầu vào để tạo ra \"2018.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Getting the attention weights from the network\n",
    "\n",
    "Bây giờ hãy hình dung các giá trị chú ý trong mạng của bạn. Chúng tôi sẽ  truyền một ví dụ thông qua mạng, sau đó trực quan hóa các giá trị của $\\alpha^{\\langle t, t' \\rangle}$. \n",
    "\n",
    "Để tìm ra vị trí của các giá trị chú ý, hãy bắt đầu bằng cách in bản tóm tắt của mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 30, 37)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "s0 (InputLayer)                  (None, 64)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional)  (None, 30, 64)        17920       input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "repeat_vector_3 (RepeatVector)   (None, 30, 64)        0           s0[0][0]                         \n",
      "                                                                   lstm_3[0][0]                     \n",
      "                                                                   lstm_3[1][0]                     \n",
      "                                                                   lstm_3[2][0]                     \n",
      "                                                                   lstm_3[3][0]                     \n",
      "                                                                   lstm_3[4][0]                     \n",
      "                                                                   lstm_3[5][0]                     \n",
      "                                                                   lstm_3[6][0]                     \n",
      "                                                                   lstm_3[7][0]                     \n",
      "                                                                   lstm_3[8][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 30, 128)       0           bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_3[0][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_3[1][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_3[2][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_3[3][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_3[4][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_3[5][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_3[6][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_3[7][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_3[8][0]            \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   repeat_vector_3[9][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 30, 10)        1290        concatenate_3[0][0]              \n",
      "                                                                   concatenate_3[1][0]              \n",
      "                                                                   concatenate_3[2][0]              \n",
      "                                                                   concatenate_3[3][0]              \n",
      "                                                                   concatenate_3[4][0]              \n",
      "                                                                   concatenate_3[5][0]              \n",
      "                                                                   concatenate_3[6][0]              \n",
      "                                                                   concatenate_3[7][0]              \n",
      "                                                                   concatenate_3[8][0]              \n",
      "                                                                   concatenate_3[9][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 30, 1)         11          dense_6[0][0]                    \n",
      "                                                                   dense_6[1][0]                    \n",
      "                                                                   dense_6[2][0]                    \n",
      "                                                                   dense_6[3][0]                    \n",
      "                                                                   dense_6[4][0]                    \n",
      "                                                                   dense_6[5][0]                    \n",
      "                                                                   dense_6[6][0]                    \n",
      "                                                                   dense_6[7][0]                    \n",
      "                                                                   dense_6[8][0]                    \n",
      "                                                                   dense_6[9][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "attention_weights (Activation)   (None, 30, 1)         0           dense_7[0][0]                    \n",
      "                                                                   dense_7[1][0]                    \n",
      "                                                                   dense_7[2][0]                    \n",
      "                                                                   dense_7[3][0]                    \n",
      "                                                                   dense_7[4][0]                    \n",
      "                                                                   dense_7[5][0]                    \n",
      "                                                                   dense_7[6][0]                    \n",
      "                                                                   dense_7[7][0]                    \n",
      "                                                                   dense_7[8][0]                    \n",
      "                                                                   dense_7[9][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dot_3 (Dot)                      (None, 1, 64)         0           attention_weights[0][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[1][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[2][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[3][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[4][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[5][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[6][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[7][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[8][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "                                                                   attention_weights[9][0]          \n",
      "                                                                   bidirectional_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "c0 (InputLayer)                  (None, 64)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    [(None, 64), (None, 6 33024       dot_3[0][0]                      \n",
      "                                                                   s0[0][0]                         \n",
      "                                                                   c0[0][0]                         \n",
      "                                                                   dot_3[1][0]                      \n",
      "                                                                   lstm_3[0][0]                     \n",
      "                                                                   lstm_3[0][2]                     \n",
      "                                                                   dot_3[2][0]                      \n",
      "                                                                   lstm_3[1][0]                     \n",
      "                                                                   lstm_3[1][2]                     \n",
      "                                                                   dot_3[3][0]                      \n",
      "                                                                   lstm_3[2][0]                     \n",
      "                                                                   lstm_3[2][2]                     \n",
      "                                                                   dot_3[4][0]                      \n",
      "                                                                   lstm_3[3][0]                     \n",
      "                                                                   lstm_3[3][2]                     \n",
      "                                                                   dot_3[5][0]                      \n",
      "                                                                   lstm_3[4][0]                     \n",
      "                                                                   lstm_3[4][2]                     \n",
      "                                                                   dot_3[6][0]                      \n",
      "                                                                   lstm_3[5][0]                     \n",
      "                                                                   lstm_3[5][2]                     \n",
      "                                                                   dot_3[7][0]                      \n",
      "                                                                   lstm_3[6][0]                     \n",
      "                                                                   lstm_3[6][2]                     \n",
      "                                                                   dot_3[8][0]                      \n",
      "                                                                   lstm_3[7][0]                     \n",
      "                                                                   lstm_3[7][2]                     \n",
      "                                                                   dot_3[9][0]                      \n",
      "                                                                   lstm_3[8][0]                     \n",
      "                                                                   lstm_3[8][2]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 11)            715         lstm_3[0][0]                     \n",
      "                                                                   lstm_3[1][0]                     \n",
      "                                                                   lstm_3[2][0]                     \n",
      "                                                                   lstm_3[3][0]                     \n",
      "                                                                   lstm_3[4][0]                     \n",
      "                                                                   lstm_3[5][0]                     \n",
      "                                                                   lstm_3[6][0]                     \n",
      "                                                                   lstm_3[7][0]                     \n",
      "                                                                   lstm_3[8][0]                     \n",
      "                                                                   lstm_3[9][0]                     \n",
      "====================================================================================================\n",
      "Total params: 52,960\n",
      "Trainable params: 52,960\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Điều hướng qua đầu ra của `model.summary()` above. Bạn có thể thấy rằng lớp có tên `attention_weights` xuất ra `alphas` of shape (m, 30, 1) before `dot_2` tính toán vectơ ngữ cảnh cho mỗi bước thời gian  $t = 0, \\ldots, T_y-1$. Hãy lấy trọng số chú ý từ lớp này.\n",
    "\n",
    "The function `attention_map()` lấy ra các giá trị chú ý từ mô hình của bạn và vẽ chúng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc83e271518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAGsCAYAAAD9ro91AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngju/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc6c47bfa58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_map = plot_attention_map(model, human_vocab, inv_machine_vocab, \"Saturday May 9 2018\", num = 7, n_s = 64);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trên biểu đồ đã tạo, bạn có thể quan sát các giá trị của trọng số chú ý cho mỗi ký tự của kết quả dự đoán. Kiểm tra âm mưu này và kiểm tra xem những nơi mà mạng đang chú ý có hợp lý với bạn không.\n",
    "\n",
    "Trong ứng dụng dịch ngày, bạn sẽ thấy rằng phần lớn thời gian chú ý giúp dự đoán năm và không có nhiều tác động đến việc dự đoán ngày hoặc tháng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations!\n",
    "\n",
    "\n",
    "You have come to the end of this assignment \n",
    "\n",
    "## Here's what you should remember\n",
    "\n",
    "- Các mô hình dịch máy có thể được sử dụng để ánh xạ từ chuỗi này sang chuỗi khác. Chúng hữu ích không chỉ để dịch ngôn ngữ của con người (như tiếng Pháp-> tiếng Anh) mà còn cho các tác vụ như dịch định dạng ngày tháng.\n",
    "- Cơ chế chú ý cho phép mạng tập trung vào các phần có liên quan nhất của đầu vào khi xuất một phần cụ thể của đầu ra.\n",
    "- Mạng sử dụng cơ chế chú ý có thể dịch từ các đầu vào có độ dài $T_x$ đến đầu ra có độ dài $T_y$, where $T_x$ and $T_y$ can be different. \n",
    "- Bạn có thể hình dung trọng số chú ý $\\alpha^{\\langle t,t' \\rangle}$ để xem mạng đang chú ý đến điều gì trong khi tạo từng đầu ra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "n16CQ",
   "launcher_item_id": "npjGi"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
