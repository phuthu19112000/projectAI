{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Photometric calibration\n",
    "\n",
    "- Before we can successfully merge multiple photographs, we need to characterize the functions that map incoming irradiance into pixel values and also the amount of noise present in each image\n",
    "\n",
    "- In this section, we examine three components of the imaging pipeline that affect this mapping:\n",
    "    - radiometric response function: which maps photons arriving at the lens into digital values stored in the image file\n",
    "    - vignetting: which darkens pixel values near the periphery of images, especially at large apertures\n",
    "    - point spread function: which characterizes the blur induced by the lens, anti-aliasing filters, and finite sensor areas\n",
    "\n",
    "#### 10.1.1 Radiometric response function\n",
    "#### 10.1.2 Noise level estimation\n",
    "#### 10.1.3 Vignetting\n",
    "#### 10.1.4 Optical blur (spatial response) estimation\n",
    "\n",
    "### 10.2 High dynamic range (HDR) imaging\n",
    "\n",
    "- As we mentioned earlier in this chapter, registered images taken at different exposures can be\n",
    "used to calibrate the radiometric response function of a camera. More importantly, they can\n",
    "help you create well-exposed photographs under challenging conditions, such as brightly lit\n",
    "scenes where any single exposure contains saturated (overexposed) and dark (underexposed)\n",
    "regions\n",
    "\n",
    "![](./images/i13.png)\n",
    "\n",
    "![](./images/i14.png)\n",
    "\n",
    "- Instead, the more common approach is to proceed in three stages:\n",
    "    1. Estimate the radiometric response function from the aligned images\n",
    "    2. Estimate a radiance map by selecting or blending pixels from different exposures\n",
    "    3. Tone map the resulting high dynamic range (HDR) image back into a displayable gamut"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Super-resolution, denoising, and blur removal\n",
    "- super-resolution enables us to create images with higher spatial resolution and less noise than regular camera images. The latest trend in super-resolution has been the use of deep neural networks to directly predict super-resolved images\n",
    "\n",
    "- Single and multi-frame denoising: The latest benchmark for comparing image denoising algorithms,  the NTIRE 2020 Challenge on Real Image Denoising  is based on a smartphone image denoising dataset (SIDD)\n",
    "\n",
    "- Blur removal\n",
    "    - Under favorable conditions, super-resolution and related upsampling techniques can increase the resolution of a well-photographed image or image collection\n",
    "    - When the input images are blurry to start with, the best one can often hope for is to reduce the amount of blur\n",
    "    - [Paper with code](https://github.com/subeeshvasu/Awesome-Deblurring)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4 Image matting and compositing\n",
    "- To successfully copy a foreground object from one image to another without visible discretization artifacts, we need to pull a matte i.e., to estimate a soft opacity channel α and the uncontaminated foreground colors F from the input composite image C\n",
    "\n",
    "#### 10.4.1 Blue screen matting\n",
    "- Two-screen matting\n",
    "- Difference matting\n",
    "\n",
    "#### 10.4.2 Natural image matting\n",
    "\n",
    "![](./images/i15.png)\n",
    "\n",
    "- The most general version of image matting is when nothing is known about the background except, perhaps, for a rough segmentation of the scene into foreground, background, and unknown regions, which is known as the trimap\n",
    "\n",
    "#### 10.4.3 Optimization-based matting\n",
    "\n",
    "- An alternative to estimating each pixel’s opacity and foreground color independently is to use\n",
    "global optimization to compute a matte that takes into account correlations between neighboring α values:\n",
    "    - GrabCut interactive segmentation system\n",
    "    - Poisson Matting\n",
    "\n",
    "- [Image Matting paper with code](https://github.com/michaelowenliu/awesome-image-matting)\n",
    "\n",
    "- [The latest results on natural image matting](http://alphamatting.com). It currently lists over 60 different algorithms, with most of the more recent algorithms using deep neural network\n",
    "\n",
    "#### 10.4.5 Video matting\n",
    "- In follow-up work Lin, Ryabtsev et al. (2021) describe a [high-resolution real-time video matting system.](https://github.com/PeterL1n/BackgroundMattingV2?utm_source=catalyzex.com)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5 Simultaneous localization and mapping (SLAM)\n",
    "- [ARKit](https://developer.apple.com/augmented-reality) \n",
    "- [ARCore](https://developers.google.com/ar)\n",
    "- [Spark AR](https://sparkar.facebook.com/ar-studio)\n",
    "#### 11.5.1 Application: Autonomous navigation\n",
    "#### 11.5.2 Application: Smartphone augmented reality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
